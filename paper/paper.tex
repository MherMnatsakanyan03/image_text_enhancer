\documentclass[sigconf]{acmart}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{url}


%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% These commands are for a PROCEEDINGS abstract or paper.
\settopmatter{printacmref=true} % Removes citation information below abstract
%% Was false before, we need to check why its not working as intended
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in 

\acmConference[AEPRO 2026]{AEPRO 2026: Algorithm Engineering Projects}{March 1}{Jena, Germany}

% convert text to title case
% http://individed.com/code/to-title-case/

% that helps you to formulate your sentences
% https://www.deepl.com/translator

\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
%% TODO: think about good title
\title[Image Text Enhancer]{Image Text Enhancer}
\subtitle{\large Algorithm Engineering 2026 Project Paper}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.

\author{Daniel Motz}
\affiliation{%
  \institution{Friedrich Schiller University Jena}
  \city{Jena}
  \country{Germany}}
\email{daniel.motz@uni-jena.de}

\author{Leonard Teschner}
\affiliation{%
  \institution{Friedrich Schiller University Jena}
  \city{Jena}
  \country{Germany}}
\email{leonard.teschnner@uni-jena.de}

\author{Mher Mnatsakanyan}
\affiliation{%
  \institution{Friedrich Schiller University Jena}
  \city{Jena}
  \country{Germany}}
\email{mher.mnatsakanyan@uni-jena.de}

%% The abstract is a short summary of the work to be presented in the article.
\begin{abstract}

The five-finger pattern:
\begin{enumerate}
\item \textbf{Topic and background:} What topic does the paper deal with? What is the point of departure for your research? Why are you studying this now?
\item \textbf{Focus:} What is your research question? What are you studying precisely?
\item \textbf{Method:} What did you do?
\item \textbf{Key findings:} What did you discover?
\item \textbf{Conclusions or implications:} What do these findings mean? What broader issues do they speak to?
\end{enumerate}


\end{abstract}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{noise reduction, background removal, image filter, binarization}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
\label{sec:intro}

\subsection{Background}
\label{sec:background}

In the age of digitalisation, many printed, handwritten and historical documents are digitised using a scanner or handheld smartphone camera. This often results in poor-quality images that are not suitable for digital image processing methods such as text recognition. \cite{Investigation_binarization_techniques_unevenly_illuminated_document_images_alqudah_2015,review_document_binarization_yang_2024,review_degradation_image_enhancement_zhou_2023}.
There are different challenges that can arise during digitization, depending on the type of capture method and the type of document: documents scanned with a smartphone camera cannot capture all the details that a dedicated document scanner can. This results in blurry and distorted images. The angle and distance of the camera from the document also affect the quality. Lighting conditions may cause shadows, glare, and reflections. Furthermore, smartphone cameras may capture text that does not belong to the scanned document itself. Distorted perspectives and text alignment problems can occur \cite{comprehensive_review_document_image_binarization_bataineh_2025, Investigation_binarization_techniques_unevenly_illuminated_document_images_alqudah_2015}.
Historical documents in particular are of great interest for digitization. They can then be preserved and analyzed by digitalization and text recognition. However, due to their age, storage conditions, and the way they were created, they frequently suffer from deterioration. They are subject to fading and noise, which can make the text illegible for Humans and aswell for computer programms. Handwritten notes, overlapping text, stylistic variations, damaged pages, tears, and mold spots make digitization more complex \cite{comprehensive_review_document_image_binarization_bataineh_2025,degraded_historical_document_binarization_sulaiman_2019}.

\subsection{Related Work}
\label{sec:related-work}
\begin{comment}
  Tools die binarisierung bereits können:
  - OpenCV
  - Tesseract
  - Leptonica - von copilopt vorgeschlagen
  - ImageMagick
\end{comment}

\begin{comment}
  Diese Paper wurden nicht von mir gelesen, aber in \cite{review_document_binarization_yang_2024} als beispiel für die verschiedenen Kategorien von Binarisierungsmethoden genannt:
  \cite{Yang2008}, \cite{Lu2010}, cite{Tong2009}
\end{comment}

When improving images and analyzing digitized documents using OCR text recognition and other recognition systems, segmenting the background and foreground is an essential step \cite{review_document_binarization_yang_2024}. Segmentation is implemented using binarization. There are traditional methods for binarization, which use a global \cite{Otsu1979}, local \cite{adaptive_thresholding_methods_bataineh_2011, adaptive_thresholding_integral_image_bradley_roth_2007, image_binarization_sauvola_2000} or mixed thresholds \cite{Yang2008, review_document_binarization_yang_2024}. These are used to classify the pixels as foreground and background, pixel by pixel. Image feature methods such as edge detection \cite{Lu2010, review_document_binarization_yang_2024} and fuzzy logic \cite{Tong2009, review_document_binarization_yang_2024} have also been used for binarization. In recent years, deep learning binarization methods have been evolved in addition to the traditional methods. These are based on convolutional neural networks, generative adversarial networks, or attention mechanisms \cite{review_document_binarization_yang_2024}. 

In addition to methods that solely rely on binarization, there are approaches that combine several image processing methods to improve the quality of text images. For example, Alqudah et al. \cite{Investigation_binarization_techniques_unevenly_illuminated_document_images_alqudah_2015} present a pipeline that combines entropy filters and morphological operations with binarization. In \cite{image_binarization_end_to_end_text_understanding_milyaev_2013} Niblack's binarization is combined with a Laplace edge filter and global optimization. Another approach is described by Vlasceanu et al. \cite{voting_method_image_binarization_vlasceanu_2022}. This approach combines different binarization methods and uses a voting mechanism to decide which pixels should be assigned to the foreground or background.

\begin{comment}
  Noch etwas für Denoising und andere bildverbesserungsmethoden, wie deskewing, erosion/dilation, despeckle etc.?
\end{comment}

\subsection{Our Contribution}
\label{sec:our-contribution}

To improve scanned and photographed text images, we present a pipeline that combines several image processing methods. It includes steps such as deskewing, contrast enhancement, noise reduction, binarization, despeckle, and morphological operations. The binarized result of the pipeline can also be converted back into a color image.

The pipeline is modular and user-friendly. Users can select the steps they want to apply to customize the pipeline to their specific use cases. Although the method parameters can be customized individually, they are configured with best practice values by default to ensure a high level of user-friendliness.

\begin{comment}
  Uns ist die effiziente Verarbeitung in der Pipeline wichtig. Daher vergleichen wir uns mit traditionellen open-source Binarisierungsmethoden und Bildverbesserungsverfahren und lassen bewusst Deep Learning Ansätze, sowie zahlungspflichtige Software außen vor.
\end{comment}

The pipeline is provided both as a executable and as a C++ library containing the individual methods. To efficiently process large amounts of image data, the implementation uses parallelization via OpenMP and other optimization methods such as loop blocking. The CImg library \cite{cimg} is used for the basic image processing methods.

\subsection{Outline}
\label{sec:outline}

\begin{comment}
  welche experimente werden wir durchführen?
\end{comment}

This paper is structured as follows: Section \ref{sec:pipeline} provides a detailed description of the developed pipeline and its methods. Section \ref{sec:experiments} demonstrates the performance of our pipeline using experiments. Finally, Section \ref{sec:conclusions} summarises our results and provides an outlook on possible future work.

\section{The Pipeline}
\label{sec:pipeline}

Many approaches and best practices already exist for improving the quality of scanned images as seen in section \ref{sec:related-work}. We have developed a pipeline that combines several of these methods in order to achieve \textbf{potentially} good results. Users can choose which steps to apply from the pipeline. The individual methods of the pipeline are shown in algorithm \ref{alg:enhance}.
 
\begin{algorithm}
  \caption{Image Text Enhance Pipeline}
  \label{alg:enhance}
  \begin{enumerate}
  \item convert image to grayscale
  \item Deskew (if requested)
  \item Contrast enhancement
  \item Denoising
  \item Binarization
  \item Despeckle (if requested)
  \item Morphological operations (if requested)
  \item Color passthrough
\end{enumerate}
\end{algorithm}

The individual methods of the pipeline are explained in more detail below.

\subsection{Convert image to grayscale}
\label{subsec:grayscale}

All pipeline methods work on grayscale images. Therefore, the first step is to convert the input image into a grayscale image. This is achieved by applying the weighted sum $Y = 0.299R + 0.587G + 0.114B$, as standardised by the International Telecommunication Union \cite{ITU-R_BT601}, to each pixel. The result is a grayscale image in which the brightness value of each pixel, represented by $Y$, corresponds to that of the original RGB-pixel.
All steps in the pipeline are performed on the converted grayscale image in-place after the conversion.

\subsection{Deskew}
\label{subsec:deskew}

To ensure that the text in the image is horizontally aligned, a deskew step is performed at the user's request. Text analysis methods such as OCR benefit in particular from horizontally aligned texts \cite{novel_adaptive_deskewing_algorithm_document_images_bao_2022}. The deskewing algorithm uses the projection profile method, which is similar to the one described in \cite{automated_entry_system_printed_documents_akiyama_hagita_1990}. First the image is binarized using Sauvola's method\footnote{see section \ref{subsec:binarization} or \cite{image_binarization_sauvola_2000}}. In the second step, the angle that maximizes the variance of the horizontal projections is determined. Finally, the image is rotated by this angle to correct the skew.
The advantages of this method are that it is polarity-safe\footnote{detects light from dark backgrounds}, uses a coarse-to-fine angle search\footnote{tbc} for efficiency, and employs Neumann boundary conditions \footnote{tbc} to avoid black corners.

\subsection{Contrast enhancement}
\label{subsec:contrast-enhancement}

To correct contrast problems caused by varying lighting conditions while digitizing documents, a contrast enhancement step is performed. This helps with binarization in the further course \cite{Investigation_binarization_techniques_unevenly_illuminated_document_images_alqudah_2015}. A robust, linear contrast stretching algorithm is applied. The lower 1\% and upper 1\% of intensities are truncated to ignore outliers. The remaining range is then stretched to the full range from 0 to 255 (black to white).

\subsection{Denoising}
\label{subsec:denoising}

\begin{comment}
  - adaptive Gaussian blur
      Paper fehlt
  - adaptive median blur
      Paper fehlt
\end{comment}

Digital images are subject to noise due to the way they are captured, compressed, or transmitted, resulting in the loss of image information. The presence of noise limits the effectiveness of image analysis steps, among other things \cite{review_image_denoising_techniques_fan_2019}. Two simple and two adaptive filter methods are available for the user to choose from. 
\textit{CImg} offers two simple filtering methods, which are also available in the Pipeline: a Gaussian filter with Neumann boundary conditions and a nonlinear median filter \cite{cimg}. The Gaussian filter is a low-pass filter and thus blurs the image. The median filter is a non-linear filter that takes the pixel value that represents the median of the neighboring pixels in the window to contain edges \cite{Image_engineering_zhang_2017}. In addition to the two simple filters, two adaptive filter methods are offered. An adaptive Gaussian filter that uses a variable standard deviation to blur less at edges and blur more in flat regions with high variance. In addition to the simple median filter, an adaptive median filter is provided. This is particularly well suited for removing impulse noise (salt and pepper noise) while preserving edges and fine details. It starts with a $3\times3$ window, which is expanded to a defined maximum window size when impulse noise is detected, while non-impulse pixels remain unchanged. This makes it ideal for removing scan speckle\footnote{tbc} in text images.

\subsection{Binarization}
\label{subsec:binarization}

Segmenting the foreground and background is a good approach to improve image quality. It also represents the first step in recognition systems such as OCR \cite{review_document_binarization_yang_2024,Investigation_binarization_techniques_unevenly_illuminated_document_images_alqudah_2015}. Since binarization methods have been well researched in the literature, several are available in the pipeline for the users to choose from. All methods are thresholding methods that calculate a threshold $T$ for each pixel ($T_g$ for global and $T_w$ for local terms) and compare the pixel value $i(x,y)$ with the threshold. This type of binarization is simple and efficient \cite{comprehensive_review_document_image_binarization_bataineh_2025}. 

The simplest method is the Otsu method \cite{Otsu1979}, which calculates a global threshold while minimizing the intraclass variance. This is shown in equations \eqref{eq:1} and \eqref{eq:2}, where $w1(t)$ and $w2(t)$ are the probabilities of the two classes (foreground and background) and $\sigma^2\_1(t),\sigma^2\_2(t)$ are the variances of the two classes. This makes the method efficient, but also susceptible to overlaps and poor intensity distributions \cite{comprehensive_review_document_image_binarization_bataineh_2025}.

\begin{gather}
  \sigma^2\_w(t) = w1(t) * \sigma^21(t) + w2(t) * \sigma^2\_2(t) \label{eq:1} \\
  T_g=\underset{t}{\operatorname{argmin}}\ \sigma^2\_w(t) \label{eq:2}
\end{gather}

\begin{comment}
  R = max stddev value (typically 128 for 8-bit images)
\end{comment}

One adaptive local threshold approach is the Sauvola method \cite{image_binarization_sauvola_2000}. This method calculates a local threshold $T_w$ for each pixel in a window around that pixel. This method is resistant to uneven lighting. The local mean $m_w$ and local standard deviation $\sigma_w$ of the window are used, as well as the parameter $R$, which represents the dynamic range of the standard deviation. The sensitivity of the threshold can be corrected using the parameter $k$. The threshold is represented in equation \eqref{math:sauvola} \cite{review_document_binarization_yang_2024,image_binarization_sauvola_2000}. An optional parameter $delta$ has been added to further fine-tune the threshold.
\begin{gather}
  T_w = m_w * \left(1 + k * \left(\frac{\sigma_w}{R} - 1\right)\right) - delta \label{math:sauvola}
\end{gather}

\begin{comment}
  ToDo: evtl. noch k in die T Formel einbauen, um die Sensitivität anzupassen
\end{comment}

Another adaptive method that dynamically adjusts the required window size is the method developed by Bataineh et al. \cite{adaptive_thresholding_methods_bataineh_2011}. This method first calculates a global threshold $T_{con}$ \eqref{math:adapt_win:T_con}, which classifies the pixel values into foreground (black), background (white), and confusion values (red) \eqref{math:adapt_win:I}. Based on the ratio $p$ of foreground to confusion values and the global standard deviation $\sigma_g$, a primary window size $PW_{size}$ is selected \eqref{math:adapt_win:PW}. If the number of confusion values in the window exceeds the number of foreground values, half the window size $SW_{size}$ is used.

\begin{gather}
  T_{con} = m_g - \frac{m_g^2 * \sigma_g}{(m_g + \sigma_g) * (0.5 max_{level} + \sigma_g)}\label{math:adapt_win:T_con}\\
  I = \begin{cases}
    \text{black}, &  i(x,y) \leq T_{con} - \left(\frac{\sigma_g}{2}\right),\\
    \text{red}, &  T_{con} - \left(\frac{\sigma_g}{2}\right) < i(x,y) < T_{con} + \left(\frac{\sigma_g}{2}\right),\\
    \text{white}, &  i(x, y) \geq T_{con} + \left(\frac{\sigma_g}{2}\right),\\
  \end{cases} \label{math:adapt_win:I}\\
  PW_{size} = \begin{cases}
    \left(\frac{I_h}{4}, \frac{I_w}{6}\right), &  p \geq 2.5 \ \text{ or } \ (\sigma_g < 0.1 * max_{level}),\\
    \left(\frac{I_h}{30}, \frac{I_w}{20}\right), &  1 < p < 2-5 \ \text{or} \ (I_h + I_w < 400),\\
    \left(\frac{I_h}{40}, \frac{I_w}{30}\right), & p \leq 1,
  \end{cases}\label{math:adapt_win:PW}
\end{gather}

The local threshold $T_w$ is then calculated for each window \eqref{math:bataineh}. This uses an adaptive standard deviation value $\sigma_{adaptive}$ based on the maximum and minimum values of the standard deviation of all windows \eqref{math:bataineh:adapt} \cite{adaptive_thresholding_methods_bataineh_2011}. Due to the adaptive window size and adaptive threshold value, which are based on the image features, this method is robust against various challenges such as thin pen strokes and low-contrast images. However, excessive background remains unavoidable \cite{review_document_binarization_yang_2024}.

\begin{gather} 
  T_w = m_w - \frac{m_W^2-\sigma_W}{(m_g+\sigma_W) \times (\sigma_{adaptive}+\sigma_W)}\label{math:bataineh} \\
  \sigma_{adaptive} = \frac{\sigma_W-\sigma_{min}}{\sigma_{max}-\sigma_{min}} \label{math:bataineh:adapt}
\end{gather}

\subsection{Despeckle}
\label{subsec:despeckle}

A despeckle step is offered to remove small spots that arise or remain during binarization. It removes smaller, connected components (speckles) from the binarized image.
The method $get\_label\text{()}$ from the CImg library \cite{cimg} is used to detect the connected components. It calculates the connected components using the algorithm by Hesselinks et al. \cite{connected_components_hesselink_meijster_bron_2001,cimg}.

\subsection{Morphological operations}
\label{subsec:morphological-operations}

After segmenting the foreground and background, small holes or islands may appear. These can be removed using opening and closing operations \cite{image_engineering_vl2_zhang_2017}. The pipeline offers the option of applying the morphological operations dilation and erosion. Dilation expands bright (white) areas. In binary images, this can connect broken characters or thicken strokes. Erosion reduces bright areas \footnote{and expands dark areas}. In binary images, this can remove small noise points or make strokes thinner \cite{Digitale_Bildverarbeitung_werner_2020,image_engineering_vl2_zhang_2017}.

\subsection{Color passthrough}
\label{subsec:color-passthrough}

As the final step in the pipeline, the binarized image can be used to obtain the color values of the original image. To do this, the binarized and enhanced image is used as a mask. All pixels that were classified as foreground (black) in the binarized image are replaced by the color of the underlying pixel in the original image. As shown in equation \eqref{math:color}, $I'(x, y, z)$ describes the result, $I_{original}(x, y, z)$ describes the colored original image, and $i(x, y)$ describes the binarized image.

\begin{gather}
  I'(x, y, z) =
  \begin{cases}
    I_{original}(x, y, z), & \text{if }i(x, y) = \text{black},\\
    \text{white}, & \text{else} 
  \end{cases} \label{math:color}
\end{gather}

\section{Experiments}
\label{sec:experiments}

\begin{comment}
  In der Literatur wird die Binarisierung durch Benchmark Datasets evaluiert, die ground truth Bilder enthalten. Es ergibt aber keinen Sinn für unserer Pipeline diese zu nutzen, da wir nicht nur binarisieren, sondern auch andere Schritte durchführen.
\end{comment}

\begin{comment}
  Wir werden die performance (Laufzeit) der Pipeline anhand verschiedener Einstellungen testen. Bspw. unterschiediche Anzahl an Threads, verschieden große Bilder, verschiedene Kombinationen von Methoden.
\end{comment}


\section{Conclusions}
\label{sec:conclusions}


%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{literature}


\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
