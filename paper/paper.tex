\documentclass[sigconf]{acmart}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{url}


%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% These commands are for a PROCEEDINGS abstract or paper.
\settopmatter{printacmref=false} % Removes citation information below abstract
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in 

\acmConference[AEPRO 2026]{AEPRO 2026: Algorithm Engineering Projects}{March 1}{Jena, Germany}

% convert text to title case
% http://individed.com/code/to-title-case/

% that helps you to formulate your sentences
% https://www.deepl.com/translator

\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
%% TODO: think about good title
\title[Image Text Enhancer]{Image Text Enhancer\\\large Algorithm Engineering 2026 Project Paper}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.

\author{Daniel Motz}
\affiliation{%
  \institution{Friedrich Schiller University Jena}
  \country{Germany}}
\email{daniel.motz@uni-jena.de}

\author{Leonard Teschner}
\affiliation{%
  \institution{Friedrich Schiller University Jena}
  \country{Germany}}
\email{leonard.teschnner@uni-jena.de}

\author{Mher Mnatsakanyan}
\affiliation{%
  \institution{Friedrich Schiller University Jena}
  \country{Germany}}
\email{mher.mnatsakanyan@uni-jena.de}

%% The abstract is a short summary of the work to be presented in the article.
\begin{abstract}

The five-finger pattern \cite{macgilchrist2014}:
\begin{enumerate}
\item \textbf{Topic and background:} What topic does the paper deal with? What is the point of departure for your research? Why are you studying this now?
\item \textbf{Focus:} What is your research question? What are you studying precisely?
\item \textbf{Method:} What did you do?
\item \textbf{Key findings:} What did you discover?
\item \textbf{Conclusions or implications:} What do these findings mean? What broader issues do they speak to?
\end{enumerate}


\end{abstract}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{noise reduction, background removal, image filter, binarization}


%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\let\thefootnote\relax\footnotetext{AEPRO 2026, March 1, Jena, Germany. Copyright \copyright 2026 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).}

\section{Introduction}
\label{sec:intro}

\subsection{Background}
\label{sec:background}
\begin{comment}
  Motivation:
  - Viele handschriftliche oder gedruckte Dokumente werden heutzutage mit dem Smartphone, oder im Zuge der Digitalisierung mit Druckern gescannt. Dabei entstehen häufig Bilder mit schlechter Qualität, die schwer lesbar, für Mensch und Maschine sind. Schlechte Qualität ist in diesem Kontext durch schlechte Beleuchtung, Schatten, Verzerrungen, Rauschen oder ungleichmäßigen Kontrast gekennzeichnet.
  - Solche Bilder sind problematisch, wenn sie weiterverwendet werden sollen, beispielsweise um sie zu archivieren, zu drucken oder mittels OCR in maschinenlesbaren Text umzuwandeln.
\end{comment}

\subsection{Related Work}
\label{sec:related-work}
\begin{comment}
  drei Paper wurden uns empfohlen:
  - Adaptive Thresholding Methods for Documents Image Binarization \cite{adaptive_thresholding_methods_bataineh_2011}: Das Bild wird in Fenster aufgeteilt. Fuer jedes Fenster wird ein Thresholdingvalue $T$ berechnet. In jedem Fenster wird die minimum $\sigma_{min}$ und maximum $\sigma_{max}$ Standardabweichungen aller Fenster verwendet, um adaptiv den Threshold $T$ zu bestimmen. Jeder Pixelwert $i(x, y)$ des Fensters wird anschliessend mit dem Threshold verglichen: Ist der Wert kleiner wird der Pixel schwarz und sonst weiss.\\

  - Adaptive Thresholding using the Integral Image \cite{adaptive_thresholding_integral_image_bradley_roth_2007}
  - Binarization of historical document images using the local maximum and minimum \cite{Binarization_historical_document_images_local_maximum_minimum_su_2010}
  \subsection{Our Contributions}
  \label{sec:our-contributions}

  Andere Arbeiten: 
  - Pipeline die die Binarisierung durch kombination verschiedener existierender Binarisierungsmethoden und einer Logik, die die Bilder der exisiterenden Methoden filtert. Anschließend wird per Voting entschieden, welcher Pixel schwarz oder weiss ist. Vor der Ausgabe wird noch ein Post-Processing Schritt durchgeführt, um kleine Fehler zu entfernen \cite{voting_method_image_binarization_vlasceanu_2022}.
  -

  Tools die binarisierung bereits können:
  - OpenCV
  - Tesseract
  - Leptonica - von copilopt vorgeschlagen
  - ImageMagick

  - kostenloses open source Tool/executable um die Qualität von gescannten Bildern zu verbessern, bevor sie beispielsweise versendet, gedruckt oder archiviert werden.
  - Verbessert die Arbeit der Related Work, indem alle Methoden in einer Pipeline kombiniert werden können. Der Nutzer hat freie entscheidung welche Operationen er durchführen möchte ... %%TODO: konkretisieren
  - Kann beispielsweise für die Digitalisierung von Büchern, Dokumenten und handschriftlichen Akten oder Notizen genutzt werden. So wird eine gute, digitale lesbarkeit und wiedervenwendung ermöglicht.
  -OpenMP und C++ Implementierung mit CMake Build System, Catch2 Unit Tests.
\end{comment}

\subsection{Outline}
\label{sec:outline}

\begin{comment}
  welche experimente werden wir durchführen?
\end{comment}

This paper is structured as follows: Section \ref{sec:algorithm} provides a detailed description the developed pipeline and its methods. Section \ref{sec:experiments} demonstrates the performance of our algorithm using experiments. Finally, Section \ref{sec:conclusions} summarises our results and provides an outlook on possible future work.

\section{The Algorithm}
\label{sec:algorithm}

Many approaches and best practices already exist for improving the quality of scanned images as seen in section \ref{sec:related-work}. We have developed a pipeline that combines several of these methods in order to achieve potentially good results. Users can choose which steps to apply from the pipeline. The individual methods of the pipeline are shown in algorithm \ref{alg:enhance}.
 

\begin{algorithm}
  \caption{Image Text Enhance Pipeline}
  \label{alg:enhance}
  \begin{enumerate}
  \item convert image to grayscale
  \item Deskew (if requested)
  \item Contrast enhancement
  \item Denoising
  \item Binarization
  \item Despeckle (if requested)
  \item Morphological operations (if requested)
\end{enumerate}
\end{algorithm}

\begin{comment}
  <-- To be included later in some variation -->
\begin{algorithm}
\caption{Our enhance Pipeline}\label{alg:enhance}
\begin{algorithmic}
\Procedure{Enhance}{input\_image, deskew, despeckle, do\_dilation, do\_erosion}
    \State result = input\_image
    \State result $\gets$ ConvertToGrayscale(result)
    \If{deskew}
        \State result $\gets$ Deskew(result)
    \EndIf
    \State result $\gets$ ContrastEnhancement(result)
    \If{do\_adaptive\_gaussian\_blur}
        \State result $\gets$ AdaptiveGaussianBlur(result)
    \ElsIf{do\_median\_blur}
        \State result $\gets$ MedianBlur(result)
    \ElsIf{do\_median\_blur}
        \State result $\gets$ MedianBlur(result)
    \ElsIf{do\_adaptive\_median}
        \State result $\gets$ AdaptiveMedian(result)
    \Else 
        \State pass 
    \EndIf
    \State result $\gets$ Denoising(result)
    \State result $\gets$ Binarization(result)
    \If{despeckle}
        \State result $\gets$ Despeckle(result)
    \EndIf
    \If{do\_dilation}
        \State result $\gets$ MorphologicalOperations(result)
    \EndIf
    \If{do\_erosion}
        \State result $\gets$ MorphologicalOperations(result)
    \EndIf
    \State \textbf{return} result
    \EndProcedure
\end{algorithmic}
\end{algorithm}
\end{comment}


The individual methods of the pipeline are explained in more detail below.

\subsection{Convert image to graysacle}
\label{subsec:grayscale}
\begin{comment}
  Noch nicht mehr schreiben, da wir ggf. noch die Möglihckeit einfbauen wollen, farbige Bilder zu verarbeiten.
\end{comment}

All pipeline methods work on grayscale images. Therefore, the first step is to convert the input image into a grayscale image. This is achieved by applying the weighted sum $Y = 0.299R + 0.587G + 0.114B$, as defined by the International Telecommunication Union \cite{ITU-R_BT601}, to each pixel. The result is a grayscale image in which the brightness value of each pixel, represented by $Y$, corresponds to that of the original RGB-pixel.
All steps in the pipeline are performed on the converted grayscale image in-place after the conversion.

\subsection{Deskew}
\label{subsec:deskew}

\begin{comment}
  Aus der header Datei
  skew (rotation)
  Nutzt die Projection Profile Methode:
  1. Converts to grayscale and binarizes (using selected binarization method)
  2. Searches fo the angle that maximizes horizontal projection variance 
  3. Rotates the image to correct the sekw

  Features
  - Polarity-safe (detects light vs. dark background)
  - Coarse-to-fine angle search for efficiency
  - Uses Neumann boundary conditions to avoid black corners
\end{comment}

\subsection{Contrast enhancement}
\label{subsec:contrast-enhancement}

\begin{comment}
  Aus der header Datei
  Applies robust linear contrast stretching in-place.
  Clips the bottom 1% and top 1% of intensities to ignore outliers, then stretches the remaining range to 0-255.
\end{comment}

\subsection{Denoising}
\label{subsec:denoising}

\begin{comment}
  Aus der header Datei
  Verschiedne Filtermehtoden werden angegeben: 
  - simple Gaussian blur
      Uses CImg's built-in blur function with Neumann boundary conditions.
  - adaptive Gaussian blur
      This function applies a Gaussian blur with a variable standard deviation.
      It blurs less around edges (high variance) and more in flat regions (low variance)to preserve sharpness while reducing noise. The image is processed in parallel in horizontal blocks.
  - median blur
      Uses CImg's built-in blur_median function

  - adaptive median blur
      The adaptive median filter is excellent for removing impulse noise (salt-and-pepper) while preserving edges and fine details. It starts with a 3x3 window and expands up to max_window_size when detecting impulse noise, leaving non-impulse pixels unchanged. This makes it ideal for scan speckle removal in text images.
\end{comment}

\subsection{Binarization}
\label{subsec:binarization}

\begin{comment}
  es werden verschiedene adaptive Binarisierungsmethoden angeboten:
  - Sauvola
      consideres local mean and standard deviation to compute a threshold for each pixel, making it robust against uneven illumination. - Paper finden
  - Bataineh mit adaptiver window größe
\end{comment}

\paragraph{Sauvola}

\begin{comment}
  k = Sauvola's parameter, controlling threshold sensivity
  delta = optional offset to fine-tune the threshold
  R = max stddev value (typically 128 for 8-bit images)
\end{comment}

\cite{image_binarization_sauvola_2000}

\begin{gather}
  T_w = m_w * \left(1 + k * \left(\frac{\sigma_w}{R} - 1\right)\right) - delta\\
  I(x,y)= \begin{cases}
    black, &  i(x,y) < T_w,\\
    white, & text{otherwise},
  \end{cases}\\
\end{gather}

\paragraph{Bataineh}
\subparagraph{Adaptive binarization using local threshold}

\begin{comment}
  m_w = local mean of the window
  sigma_W = local standard deviation of the window
  m_g = global mean of the image pixels
  needs to be calculated upfront for all windows:
    sigma_min = minimum standard deviation among all windows
    sigma_max = maximum standard deviation among all windows
  sigma_adaptive = adaptive standard deviation for the window

  ToDo: evtl. noch k in die T Formel einbauen, um die Sensitivität anzupassen
\end{comment}

\cite{adaptive_thresholding_methods_bataineh_2011}

\begin{gather}\label{math:bataineh}
  T_w = m_w - \frac{m_W^2-\sigma_W}{(m_g+\sigma_W) \times (\sigma_{adaptive}+\sigma_W)}\\
  \sigma_{adaptive} = \frac{\sigma_W-\sigma_{min}}{\sigma_{max}-\sigma_{min}}\\
  I(x,y)= \begin{cases}
    black, & \text{if } i(x,y) < T_w\\
    white, & \text{otherwise}
  \end{cases}
\end{gather}

\subparagraph{Adaptive window size}

\begin{comment}
  m_g = global mean of the image pixels
  sigma_g = global standard deviation of the image pixels
  max_level = maximum gray level of the image
  k = parameter to adjust the threshold sensitivity (based on std deviation)
  T_con = confusion threshold, of the global image
    classifies each pixel into balck (foreground), red (confusion values), or white (background )based on its intensity relative to T_con
  PW_size = primary window size for local statistics
    1. large windows: low contast or high probability of confusing images -> multi-levels, large text size, low contact images
    2. medium windows: fine and normal images or small image size
    3. small windows: degraded images
  I_h, I_w = height and width of the image
  SW_size = secondary/final window size for local statistics
    1. subimage requieres a smaller window size 
    2. otherwise use the primary window size
\end{comment}

\begin{comment}
  "Dynamic segmentation of the image into windows based on image features, determining the threshold value for each window." \cite{review_document_binarization_yang_2024}
  "It can address specific challenges, such as thin pen strokes and low-contrast images. However,it unavoidably retains excess background." \cite{review_document_binarization_yang_2024}
\end{comment}

\cite{adaptive_thresholding_methods_bataineh_2011}

\begin{gather} \label{math:adapt_win}
  T_{con} = m_g - k * \frac{m_g^2 * \sigma_g}{(m_g + \sigma_g) * (0.5 max_{level} + \sigma_g)}\\
  I = \begin{cases}
    black, &  i(x,y) \leq T_{con} - \left(\frac{\sigma_g}{2}\right),\\
    red, &  T_{con} - \left(\frac{\sigma_g}{2}\right) < i(x,y) < T_{exp} + \left(\frac{\sigma_g}{2}\right),\\
    white, &  i(x, y) \geq T_{con} + \left(\frac{\sigma_g}{2}\right),\\
  \end{cases}\\
  p = \left(\frac{\text{number of black pixels}}{\text{number of red pixels}}\right)\\
  PW_{size} = \begin{cases}
    \left(\frac{I_h}{4}, \frac{I_w}{6}\right), &  \geq 2.5 or (\sigma_g < 0.1 * max_{level}),\\
    \left(\frac{I_h}{4}, \frac{I_w}{6}\right), &  1 < p < 2-5 or (I_h + I_w < 400),\\
    \left(\frac{I_h}{4}, \frac{I_w}{6}\right), & p \leq 1,
  \end{cases}\\
  SW_{size} = \begin{cases}
    \left(\frac{PW_h}{2}, \frac{PW_w}{2}\right), & \text{red\_pixel > black\_pixel},\\
    WP_{size}, & \text{otherwise},
  \end{cases}
\end{gather}


\subsection{Despeckle}
\label{subsec:despeckle}

\begin{comment}
  Aus der header Datei
  Removes small connected components (speckles) from a binary image in-place.
  Components smaller than the threshold are removed.
  uses diagonal_connections If true, 8-connectivity; if false, 4-connectivity.
\end{comment}

\subsection{Morphological operations}
\label{subsec:morphological-operations}

\begin{comment}
  Aus der header Datei
  Es stehen zwei Operationen zur Verfügung: 
  - Dilation 
      Dilation expands bright (white) regions. On binary images, this can connect broken character parts or thicken strokes.
  - Erosion
    Erosion shrinks bright regions (expands dark regions). On binary images, this can remove small noise specks or thin strokes.
\end{comment}

\section{Experiments}
\label{sec:experiments}



\section{Conclusions}
\label{sec:conclusions}



%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{literature}


\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
