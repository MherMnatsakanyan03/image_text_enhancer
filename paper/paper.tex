\documentclass[sigconf]{acmart}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{url}


%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% These commands are for a PROCEEDINGS abstract or paper.
\settopmatter{printacmref=true} % Removes citation information below abstract
%% Was false before, we need to check why its not working as intended
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in 

\acmConference[AEPRO 2026]{AEPRO 2026: Algorithm Engineering Projects}{March 1}{Jena, Germany}

% convert text to title case
% http://individed.com/code/to-title-case/

% that helps you to formulate your sentences
% https://www.deepl.com/translator

\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
%% TODO: think about good title
\title[Image Text Enhancer]{Image Text Enhancer}
\subtitle{\large Algorithm Engineering 2026 Project Paper}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.

\author{Daniel Motz}
\affiliation{%
  \institution{Friedrich Schiller University Jena}
  \city{Jena}
  \country{Germany}}
\email{daniel.motz@uni-jena.de}

\author{Leonard Teschner}
\affiliation{%
  \institution{Friedrich Schiller University Jena}
  \city{Jena}
  \country{Germany}}
\email{leonard.teschnner@uni-jena.de}

\author{Mher Mnatsakanyan}
\affiliation{%
  \institution{Friedrich Schiller University Jena}
  \city{Jena}
  \country{Germany}}
\email{mher.mnatsakanyan@uni-jena.de}

%% The abstract is a short summary of the work to be presented in the article.
\begin{abstract}

The five-finger pattern:
\begin{enumerate}
\item \textbf{Topic and background:} What topic does the paper deal with? What is the point of departure for your research? Why are you studying this now?
\item \textbf{Focus:} What is your research question? What are you studying precisely?
\item \textbf{Method:} What did you do?
\item \textbf{Key findings:} What did you discover?
\item \textbf{Conclusions or implications:} What do these findings mean? What broader issues do they speak to?
\end{enumerate}


\end{abstract}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{noise reduction, background removal, image filter, binarization}


%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\let\thefootnote\relax\footnotetext{AEPRO 2026, March 1, Jena, Germany. Copyright \copyright 2026 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).}

\section{Introduction}
\label{sec:intro}

\subsection{Background}
\label{sec:background}

In der Zeit der Digialisierung werden viele gedruckte, handschriftliche und historische Dokumente mittels Scanner oder Smartphone-Kamera digitalisiert. Dabei entstehen häufig digitale Bilder mit schlechter Qualität, die nicht für die digitalen Verfahren der image analysis, wie text detection, geeignet sind.

Bei der digitalisierung der Bildern können unterschiedliche challenges durch die Aufnahmeart, als auch durch den Dokumententyp entstehen:
Durch Smartphone-Kameras gescannte Dokumente können nicht alle Details wie ein dedizierte Dokumenten-Scanner aufnehmen, wodurch blurry und distorted Bilder entstehen. Auch der Winkel und der Abstand der Kamere zum Dokument haben einfluss auf die Qualität. So können distorted Perspektiven und Probleme für das Text Alignment verursacht werden. Die Lichteigenschaften können Schatten werfen, glare und reflektionen hervorrufen. Zusätzlich können Smartphone-Kameras Text auffangen, der nicht zum gescannten Dokument selbst gehört \cite{comprehensive_review_document_image_binarization_bataineh_2025}\cite{Investigation_binarization_techniques_unevenly_illuminated_document_images_alqudah_2015}.

Historiesche Dokumente haben durch ihr schieres Alter Probleme. So können sie fading und noise aufweisen, die den Text unlesbar machen. Die digitalisierung der Dokumente wird komplexer durch handschriftliche Notizen, überlappende Texte und variationen im Style, sowie durch beschädigte Seiten und risse oder auch fungal spots \cite{comprehensive_review_document_image_binarization_bataineh_2025}.

\subsection{Related Work}
\label{sec:related-work}
\begin{comment}
  drei Paper wurden uns empfohlen:
  - Adaptive Thresholding Methods for Documents Image Binarization \cite{adaptive_thresholding_methods_bataineh_2011}: Das Bild wird in Fenster aufgeteilt. Fuer jedes Fenster wird ein Thresholdingvalue $T$ berechnet. In jedem Fenster wird die minimum $\sigma_{min}$ und maximum $\sigma_{max}$ Standardabweichungen aller Fenster verwendet, um adaptiv den Threshold $T$ zu bestimmen. Jeder Pixelwert $i(x, y)$ des Fensters wird anschliessend mit dem Threshold verglichen: Ist der Wert kleiner wird der Pixel schwarz und sonst weiss.\\
  - Adaptive Thresholding using the Integral Image \cite{adaptive_thresholding_integral_image_bradley_roth_2007}
  - Binarization of historical document images using the local maximum and minimum \cite{Binarization_historical_document_images_local_maximum_minimum_su_2010}
  \subsection{Our Contributions}
  \label{sec:our-contributions}

  Tools die binarisierung bereits können:
  - OpenCV
  - Tesseract
  - Leptonica - von copilopt vorgeschlagen
  - ImageMagick
\end{comment}

\begin{comment}
  Diese Paper wurden nicht von mir gelesen, aber in \cite{review_document_binarization_yang_2024} als beispiel für die verschiedenen Kategorien von Binarisierungsmethoden genannt:
  \cite{Yang2008}, \cite{Lu2010}, cite{Tong2009}
\end{comment}

Der erste Schritt bei der image analysis, wie OCR Texterkennung und Recognision Systemen, ist die Segmentierung von Hintergrund und dem Fordergrund. \cite{review_document_binarization_yang_2024}. Die Segmentierung wird druch Binarisierung durchgeführt. Es gibt Traditionelle Methoden, welche einen globalen \cite{Otsu1979}, lokalen \cite{adaptive_thresholding_methods_bataineh_2011}\cite{adaptive_thresholding_integral_image_bradley_roth_2007}\cite{image_binarization_sauvola_2000} oder auch gemixeten Threshold berechnen\cite{Yang2008}\cite{review_document_binarization_yang_2024}. Mit Image Feature Methoden wurden Edge Detection \cite{Lu2010}\cite{review_document_binarization_yang_2024} und Fuzzy Logics \cite{Tong2009}\cite{review_document_binarization_yang_2024} eingesetz. In den letzten Jahren sind zusätzlich zu den Traditionellen Methoden noch Deep learning Binarisierungsmethoden hinzugekommen. Diese beruhen auf Convulational Neural Networks, Generative Adversarial Networks oder Attention Mechanisms \cite{review_document_binarization_yang_2024}. 

Neben den reinen Binarisierungsmethoden gibt es Ansätze, die mehrere Bildverarbeitungsmethoden kombinieren, um die Qualität von Textbildern zu verbessern. So wird in \cite{Investigation_binarization_techniques_unevenly_illuminated_document_images_alqudah_2015} eine Pipeline vorgestellt, die Entropy Filter und Morphologische Operationen mit Binarisierung kombiniert. In \cite{image_binarization_end_to_end_text_understanding_milyaev_2013} wird Niblacks Binarisierung mit einem Laplace Filter und globaler Optimierung kombiniert. Ein weiterer Ansatz ist in \cite{voting_method_image_binarization_vlasceanu_2022} beschrieben, wo verschiedene Binarisierungsmethoden kombiniert werden und per Votingmechanismus entschieden wird, welcher Pixel Vorder- oder Hintergrund ist.

\subsection{Our Contribution}
\label{sec:our-contribution}

In diesem Paper stellen wir eine Pipeline vor, die mehrere Bildverarbeitungsmethoden kombiniert, um die Qualität von gescannten oder fotografierten Textbildern zu verbessern. 
Die Pipeline umfasst Schritte wie Deskewing, Kontrastverbesserung, Rauschunterdrückung, Binarisierung, Despeckle, und morphologische Operationen. Das binarisierte Ergebnis der Pipeline kann außerdem zurück in ein Farbbild konvertiert werden.

Die Pipeline ist modular und userfriendly aufgebaut, sodass Nutzer auswählen können, welche Schritte sie anwenden möchten, um die Pipeline auf ihre spezifischen Anwendungsfälle anzupassen können. Die Methodenparameter können einzeln angepasst werden, sind aber für die userfirendlyness mit den state of the art Werten standardmäßig konfiguriert. 

Uns ist die effiziente Verarbeitung in der Pipeline wichtig. Daher vergleichen wir uns mit traditionellen open-source Binarisierungsmethoden und Bildverbesserungsverfahren und lassen bewusst Deep Learning Ansätze, sowie zahlungspflichtige Software außen vor.

Wir stellen die Pipline als C++ Bibliothek, zusätzlich mit den einzelnen Methoden zur Verfügung. Die Implementierung nutzt parallelisierung durch OpenMP, sowie weitere Optimierungsmethoden wie Loop-blocking um eine effiziente Verarbeitung großer Bilddatenmengen zu gewährleisten. 

\subsection{Outline}
\label{sec:outline}

\begin{comment}
  welche experimente werden wir durchführen?
\end{comment}

This paper is structured as follows: Section \ref{sec:pipeline} provides a detailed description the developed pipeline and its methods. Section \ref{sec:experiments} demonstrates the performance of our pipeline using experiments. Finally, Section \ref{sec:conclusions} summarises our results and provides an outlook on possible future work.

\section{The Pipeline}
\label{sec:pipeline}

Many approaches and best practices already exist for improving the quality of scanned images as seen in section \ref{sec:related-work}. We have developed a pipeline that combines several of these methods in order to achieve potentially good results. Users can choose which steps to apply from the pipeline. The individual methods of the pipeline are shown in algorithm \ref{alg:enhance}.
 
\begin{algorithm}
  \caption{Image Text Enhance Pipeline}
  \label{alg:enhance}
  \begin{enumerate}
  \item convert image to grayscale
  \item Deskew (if requested)
  \item Contrast enhancement
  \item Denoising
  \item Binarization
  \item Despeckle (if requested)
  \item Morphological operations (if requested)
  \item Color passthrough
\end{enumerate}
\end{algorithm}

The individual methods of the pipeline are explained in more detail below.

\subsection{Convert image to graysacle}
\label{subsec:grayscale}

All pipeline methods work on grayscale images. Therefore, the first step is to convert the input image into a grayscale image. This is achieved by applying the weighted sum $Y = 0.299R + 0.587G + 0.114B$, as defined by the International Telecommunication Union \cite{ITU-R_BT601}, to each pixel. The result is a grayscale image in which the brightness value of each pixel, represented by $Y$, corresponds to that of the original RGB-pixel.
All steps in the pipeline are performed on the converted grayscale image in-place after the conversion.

\subsection{Deskew}
\label{subsec:deskew}

Damit der Text im Bild horizontal ausgerichtet ist, wird ein Deskew Schritt auf den wunsch des Nutzers hin durchgeführt. Besonders text analysis Methoden wie OCR profitieren von horitonal ausgerichteten Texten \cite{novel_adaptive_deskewing_algorithm_document_images_bao_2022}. Unser Deskew Algorithmus nutzt die Projection Profile Methode, die ähnlich zu \cite{automated_entry_system_printed_documents_akiyama_hagita_1990} ist. Zuerst wird das Bild in Graustufen kovertiert und mittels Sauvols Methode Binarisiert\footnote{siehe Abschnitt \ref{subsec:binarization} oder \cite{image_binarization_sauvola_2000}}. Im zweiten Schritt wird der Winkel gesucht, der die horizontale projections Varianz maximiert. Abschließend wird das Bild rotiert, um den Skew zu korrigieren. 

Die Vorteile dieser Methode sind, dass sie Polarity-safe ist\footnote{erkennt hellen vs. dunklen Hintergrund}, eine coarse-to-fine Winkelsuche für Effizienz nutzt und Neumann Randbedingungen verwendet, um schwarze Ecken zu vermeiden.

\subsection{Contrast enhancement}
\label{subsec:contrast-enhancement}

Um die unterschiedlichen Lichtverhältnisse und daraus entstandenen Kontrastprobleme bei der Digitalisierung von Dokumenten zu adressieren, wird ein Kontrasverbesserungsschritt durchgeführt. Dies hilft der Binarisierung im weiteren Verlauf \cite{Investigation_binarization_techniques_unevenly_illuminated_document_images_alqudah_2015}. Dabei wird ein robuster linearer Kontrast Streching Algorithmus angewendet. Dabei werden die unteren 1\% und oberen 1\% der Intensitäten abgeschnitten, um Ausreißer zu ignorieren. Der verbleibende Bereich wird dann auf den vollen Bereich von 0 bis 255 gestreckt.

\subsection{Denoising}
\label{subsec:denoising}

\begin{comment}
  Aus der header Datei
  Verschiedne Filtermehtoden werden angegeben: 
  - simple Gaussian blur
      Uses CImg's built-in blur function with Neumann boundary conditions.
  - adaptive Gaussian blur
      This function applies a Gaussian blur with a variable standard deviation.
      It blurs less around edges (high variance) and more in flat regions (low variance)to preserve sharpness while reducing noise. The image is processed in parallel in horizontal blocks.
  - median blur
      Uses CImg's built-in blur_median function

  - adaptive median blur
      The adaptive median filter is excellent for removing impulse noise (salt-and-pepper) while preserving edges and fine details. It starts with a 3x3 window and expands up to max_window_size when detecting impulse noise, leaving non-impulse pixels unchanged. This makes it ideal for scan speckle removal in text images.
\end{comment}

\subsection{Binarization}
\label{subsec:binarization}

\begin{comment}
  es werden verschiedene adaptive Binarisierungsmethoden angeboten:
  - Sauvola
      consideres local mean and standard deviation to compute a threshold for each pixel, making it robust against uneven illumination. - Paper finden
  - Bataineh mit adaptiver window größe
\end{comment}

\paragraph{Sauvola}

\begin{comment}
  k = Sauvola's parameter, controlling threshold sensivity
  delta = optional offset to fine-tune the threshold
  R = max stddev value (typically 128 for 8-bit images)

\begin{gather}
  T_w = m_w * \left(1 + k * \left(\frac{\sigma_w}{R} - 1\right)\right) - delta\\
  I(x,y)= \begin{cases}
    black, &  i(x,y) < T_w,\\
    white, & text{otherwise},
  \end{cases}\\
\end{gather}

\cite{image_binarization_sauvola_2000}

\end{comment}

\paragraph{Bataineh}
\subparagraph{Adaptive binarization using local threshold}

\begin{comment}
  m_w = local mean of the window
  sigma_W = local standard deviation of the window
  m_g = global mean of the image pixels
  needs to be calculated upfront for all windows:
    sigma_min = minimum standard deviation among all windows
    sigma_max = maximum standard deviation among all windows
  sigma_adaptive = adaptive standard deviation for the window

  ToDo: evtl. noch k in die T Formel einbauen, um die Sensitivität anzupassen

\begin{gather}\label{math:bataineh}
  T_w = m_w - \frac{m_W^2-\sigma_W}{(m_g+\sigma_W) \times (\sigma_{adaptive}+\sigma_W)}\\
  \sigma_{adaptive} = \frac{\sigma_W-\sigma_{min}}{\sigma_{max}-\sigma_{min}}\\
  I(x,y)= \begin{cases}
    black, & \text{if } i(x,y) < T_w\\
    white, & \text{otherwise}
  \end{cases}
\end{gather}
\cite{adaptive_thresholding_methods_bataineh_2011}
\end{comment}



\subparagraph{Adaptive window size}

\begin{comment}
  m_g = global mean of the image pixels
  sigma_g = global standard deviation of the image pixels
  max_level = maximum gray level of the image
  k = parameter to adjust the threshold sensitivity (based on std deviation)
  T_con = confusion threshold, of the global image
    classifies each pixel into balck (foreground), red (confusion values), or white (background )based on its intensity relative to T_con
  PW_size = primary window size for local statistics
    1. large windows: low contast or high probability of confusing images -> multi-levels, large text size, low contact images
    2. medium windows: fine and normal images or small image size
    3. small windows: degraded images
  I_h, I_w = height and width of the image
  SW_size = secondary/final window size for local statistics
    1. subimage requieres a smaller window size 
    2. otherwise use the primary window size
\end{comment}

\begin{comment}
  "Dynamic segmentation of the image into windows based on image features, determining the threshold value for each window." \cite{review_document_binarization_yang_2024}
  "It can address specific challenges, such as thin pen strokes and low-contrast images. However,it unavoidably retains excess background." \cite{review_document_binarization_yang_2024}

\begin{gather} \label{math:adapt_win}
  T_{con} = m_g - k * \frac{m_g^2 * \sigma_g}{(m_g + \sigma_g) * (0.5 max_{level} + \sigma_g)}\\
  I = \begin{cases}
    black, &  i(x,y) \leq T_{con} - \left(\frac{\sigma_g}{2}\right),\\
    red, &  T_{con} - \left(\frac{\sigma_g}{2}\right) < i(x,y) < T_{exp} + \left(\frac{\sigma_g}{2}\right),\\
    white, &  i(x, y) \geq T_{con} + \left(\frac{\sigma_g}{2}\right),\\
  \end{cases}\\
  p = \left(\frac{\text{number of black pixels}}{\text{number of red pixels}}\right)\\
  PW_{size} = \begin{cases}
    \left(\frac{I_h}{4}, \frac{I_w}{6}\right), &  \geq 2.5 or (\sigma_g < 0.1 * max_{level}),\\
    \left(\frac{I_h}{4}, \frac{I_w}{6}\right), &  1 < p < 2-5 or (I_h + I_w < 400),\\
    \left(\frac{I_h}{4}, \frac{I_w}{6}\right), & p \leq 1,
  \end{cases}\\
  SW_{size} = \begin{cases}
    \left(\frac{PW_h}{2}, \frac{PW_w}{2}\right), & \text{red\_pixel > black\_pixel},\\
    WP_{size}, & \text{otherwise},
  \end{cases}
\end{gather}

\cite{adaptive_thresholding_methods_bataineh_2011}

\end{comment}
\subsection{Despeckle}
\label{subsec:despeckle}

\begin{comment}
  Aus der header Datei
  Removes small connected components (speckles) from a binary image in-place.
  Components smaller than the threshold are removed.
  uses diagonal_connections If true, 8-connectivity; if false, 4-connectivity.
\end{comment}

\subsection{Morphological operations}
\label{subsec:morphological-operations}

\begin{comment}
  Aus der header Datei
  Es stehen zwei Operationen zur Verfügung: 
  - Dilation 
      Dilation expands bright (white) regions. On binary images, this can connect broken character parts or thicken strokes.
  - Erosion
    Erosion shrinks bright regions (expands dark regions). On binary images, this can remove small noise specks or thin strokes.
\end{comment}

\subsection{Color passthrough}
\label{subsec:color-passthrough}



\section{Experiments}
\label{sec:experiments}

\begin{comment}
  In der Literatur wird die Binarisierung durch Benchmark Datasets evaluiert, die ground truth Bilder enthalten. Es ergibt aber keinen Sinn für unserer Pipeline diese zu nutzen, da wir nicht nur binarisieren, sondern auch andere Schritte durchführen.
\end{comment}

\begin{comment}
  Wir werden die performance (Laufzeit) der Pipeline anhand verschiedener Einstellungen testen. Bspw. unterschiediche Anzahl an Threads, verschieden große Bilder, verschiedene Kombinationen von Methoden.
\end{comment}



\section{Conclusions}
\label{sec:conclusions}



%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{literature}


\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
